Порівняно з попередньою версією:
1. Додано аугментацію до тренувальних даних щоб збільшити їх кількість
2. Додано врахування Feature Matching Loss до процесу навчання для запобігання Mode Collapse
3. Розширено архітектуру дискримінатора шаром MinibatchDiscrimination для порівняння взаємодії між зразками в мінібатчі. Також має допомогти запобігти Mode Collapse.

# параметри моделей
p_latent_dim = 256
p_image_size = 28*28
p_negative_slope = 0.2
p_dropout = 0.3

# параметри навчання
p_epochs = 100
p_lr_g = 0.0002
p_lr_d = 0.000005
p_beta1 = 0.5
p_beta2 = 0.999
p_weight_decay = 0.00001
loss_fn = nn.BCELoss()

# лог навчання
